<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Trajectory Segmentation for Subgoal Learning</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Trajectory Segmentation for Subgoal Learning</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://yvonne511.github.io/" target="_blank">Yvonne Wu</a></span>
                <span class="author-block">
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">New York University<br>Deep Decision Making and Reinforcement Learning</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/Yvonne511/hvq_ql" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This project proposes a vector quantized segmentation model for analyzing sequential trajectory action data using hierarchical latent representations. By leveraging Residual Vector Quantization with a multi-stage architecture, the model captures long horizon behavior segments. A latent code prediction loss combined with smoothness penalties ensures interpretable and temporally consistent segment labels. I evaluate the approach on the AntMaze, PointMaze, and Scene environments, where the segmentation codes reveal meaningful structure aligned with task dynamics.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper motivation -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Motivation</h2>
        <div class="content has-text-justified">
          <p>
            This project aims to process a large corpus of unlabeled action data and accelerate learning by leveraging skill priors. By learning how to decompose complex tasks into simpler subgoals, the model supports more efficient training through hierarchical reinforcement learning.
          </p>
          <p>
            This work is guided by two central questions:
          </p>
          <ul>
            <li><strong>How can we learn unsupervised action segmentation?</strong></li>
            <li><strong>Do better subgoals accelerate learning?</strong></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Model Pipeline -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Model Pipeline</h2>
        <div class="columns is-centered">
          <div class="column is-half">
            <figure class="image">
              <img src="static/images/model architecture.png" alt="Action Binning and Encoding">
            </figure>
          </div>
          <div class="column is-half">
            <figure class="image">
              <img src="static/images/hiql.png" alt="HIQL">
            </figure>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Experiments & Results</h2>

    <!-- Row 1 -->
    <div class="columns is-centered">
      <div class="column is-one-third has-text-centered">
        <figure class="image">
          <img src="static/images/pointmaze_segmentation.png" alt="AntMaze segmentation example" style="max-width: 100%; height: auto;">
          <figcaption>Segmented trajectories on PointMaze: distinct subgoals up down left right emerge.</figcaption>
        </figure>
      </div>
      <div class="column is-one-third has-text-centered">
        <figure class="image">
          <img src="static/images/antmaze_segmentation.png" alt="PointMaze visualization" style="max-width: 100%; height: auto;">
          <figcaption>AntMaze latent codes reflect turning points and corner navigation.</figcaption>
        </figure>
      </div>
      <div class="column is-one-third has-text-centered">
        <figure class="image">
          <img src="static/images/antmaze_before.png" alt="Scene latent bins" style="max-width: 100%; height: auto;">
          <figcaption>AntMaze segmentation before chunk action data: capture fine-grained forward, left, right motion.</figcaption>
        </figure>
      </div>
    </div>

    <!--Video Row-->
    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns">
          <div class="column is-half">
            <div class="video-container">
              <video controls style="width: 100%; height: auto;">
                <source src="static/video/task4_put_in_drawer_8.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <p class="has-text-centered">Scene segmentation</p>
            </div>
          </div>
          <div class="column is-half">
            <div class="video-container">
              <video controls style="width: 100%; height: auto;">
                <source src="static/videos/task5_put_in_drawer_8.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <p class="has-text-centered">Scene</p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Row 2 -->
    <div class="columns is-centered">
      <div class="column is-one-third has-text-centered">
        <figure class="image">
          <img src="static/images/result4.png" alt="Evaluation metric" style="max-width: 100%; height: auto;">
          <figcaption>Improved segmentation purity over baselines using HVQ.</figcaption>
        </figure>
      </div>
      <div class="column is-one-third has-text-centered">
        <figure class="image">
          <img src="static/images/result5.png" alt="Skill recovery" style="max-width: 100%; height: auto;">
          <figcaption>Recovered skill primitives match ground truth behavior stages.</figcaption>
        </figure>
      </div>
      <div class="column is-one-third has-text-centered">
        <figure class="image">
          <img src="static/images/result6.png" alt="Generalization example" style="max-width: 100%; height: auto;">
          <figcaption>Model generalizes to unseen task configurations.</figcaption>
        </figure>
      </div>
    </div>

  </div>
</section>

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <h4 class="title is-5">References</h4>
          <ul>
            <li>Investigating Enhancements to Contrastive Predictive Coding for Human Activity Recognition</li>
            <li>Hierarchical Vector Quantization for Unsupervised Action Segmentation</li>
            <li>FAST: Efficient Action Tokenization for Vision-Language-Action Models</li>
            <li>Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration</li>
            <li>Accelerating Reinforcement Learning with Learned Skill Priors</li>
            <li>Subwords as Skills: Tokenization for Sparse-Reward Reinforcement Learning</li>
            <li>HIQL: Offline Goal-Conditioned RL with Latent States as Actions</li>
            <li>OGBench</li>
          </ul>

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
